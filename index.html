
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>CephNotes</title>
  <meta name="author" content="Laurent Barbe">

  
  <meta name="description" content="Make a simple simulation ! Use your own crushmap : $ ceph osd getcrushmap -o crushmap got crush map from osdmap epoch 28673 Or create a sample &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://cephnotes.ksperis.com">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="CephNotes" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="/stylesheets/tables.css" media="screen, projection" rel="stylesheet" type="text/css" />


  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-42826829-2']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">CephNotes</a></h1>
  
    <h2><h2>Some notes about Ceph<br>Laurent Barbe @CCM Benchmark</h2></h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="as_sitesearch" value="cephnotes.ksperis.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/07/28/how-many-mouvement-when-i-add-a-replica/">How Many Mouvement When I Add a Replica ?</a></h1>
    
    
      <p class="meta">
        








  



<time datetime="2017-07-28T15:15:46+02:00" pubdate data-updated="true" class="updated">Jul 28<span>th</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Make a simple simulation !</p>

<p>Use your own crushmap :</p>

<pre><code>$ ceph osd getcrushmap -o crushmap 

got crush map from osdmap epoch 28673
</code></pre>

<p>Or create a sample clushmap :</p>

<pre><code>$ crushtool --outfn crushmap --build --num_osds 36 host straw 12 root straw 0

2017-07-28 15:01:16.240974 7f4dda123760  1 
ID  WEIGHT  TYPE NAME
-4  36.00000    root root
-1  12.00000        host host0
0   1.00000         osd.0
1   1.00000         osd.1
2   1.00000         osd.2
3   1.00000         osd.3
4   1.00000         osd.4
5   1.00000         osd.5
6   1.00000         osd.6
7   1.00000         osd.7
8   1.00000         osd.8
9   1.00000         osd.9
10  1.00000         osd.10
11  1.00000         osd.11
-2  12.00000        host host1
12  1.00000         osd.12
13  1.00000         osd.13
14  1.00000         osd.14
15  1.00000         osd.15
16  1.00000         osd.16
17  1.00000         osd.17
18  1.00000         osd.18
19  1.00000         osd.19
20  1.00000         osd.20
21  1.00000         osd.21
22  1.00000         osd.22
23  1.00000         osd.23
-3  12.00000        host host2
24  1.00000         osd.24
25  1.00000         osd.25
26  1.00000         osd.26
27  1.00000         osd.27
28  1.00000         osd.28
29  1.00000         osd.29
30  1.00000         osd.30
31  1.00000         osd.31
32  1.00000         osd.32
33  1.00000         osd.33
34  1.00000         osd.34
35  1.00000         osd.35
</code></pre>

<p>Simulate the rule 0 or your own :</p>

<pre><code>$ crushtool --test -i crushmap --rule 0 --show-mappings --min-x 0 --max-x 10 --num-rep 2

CRUSH rule 0 x 0 [0,12]
CRUSH rule 0 x 1 [5,24]
CRUSH rule 0 x 2 [9,14]
CRUSH rule 0 x 3 [30,11]
CRUSH rule 0 x 4 [20,10]
CRUSH rule 0 x 5 [28,0]
CRUSH rule 0 x 6 [6,34]
CRUSH rule 0 x 7 [19,31]
CRUSH rule 0 x 8 [17,26]
CRUSH rule 0 x 9 [9,20]
CRUSH rule 0 x 10 [10,33]

crushtool --test -i crushmap --rule 0 --show-mappings --min-x 0 --max-x 10 --num-rep 3

CRUSH rule 0 x 0 [0,12,32]
CRUSH rule 0 x 1 [5,24,20]
CRUSH rule 0 x 2 [9,14,28]
CRUSH rule 0 x 3 [30,11,13]
CRUSH rule 0 x 4 [20,10,31]
CRUSH rule 0 x 5 [28,0,12]
CRUSH rule 0 x 6 [6,34,14]
CRUSH rule 0 x 7 [19,31,6]
CRUSH rule 0 x 8 [17,26,5]
CRUSH rule 0 x 9 [9,20,30]
CRUSH rule 0 x 10 [10,33,12]
</code></pre>

<p>In general it&rsquo;s going well. But in some cases it could be better to test.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/03/03/dealing-with-some-osd-timeouts/">Dealing With Some Osd Timeouts</a></h1>
    
    
      <p class="meta">
        








  



<time datetime="2017-03-03T11:55:58+01:00" pubdate data-updated="true" class="updated">Mar 3<span>rd</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In some cases, some operations may take a little longer to be processed by the osd. And the operation may fail, or even make the OSD to suicide.
There are many parameters for these timeouts. Some examples :</p>

<h2>Thread suicide timed out</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>heartbeat_map is_healthy 'OSD::osd_op_tp thread 0x7f1ee3ca7700' had suicide timed out after 150
</span><span class='line'>common/HeartbeatMap.cc: In function 'bool ceph::HeartbeatMap::_check(ceph::heartbeat_handle_d*, const char*, time_t)' thread 7f1f0c2a3700 time 2017-03-03 11:03:46.550118
</span><span class='line'>common/HeartbeatMap.cc: 79: FAILED assert(0 == "hit suicide timeout")</span></code></pre></td></tr></table></div></figure>


<p>In ceph.conf :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[osd]
</span><span class='line'>osd_op_thread_suicide_timeout = 900</span></code></pre></td></tr></table></div></figure>


<h2>Operation thread timeout</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>heartbeat_map is_healthy 'OSD::osd_op_tp thread 0x7fd306416700' had timed out after 15</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ceph tell osd.XX injectargs --osd-op-thread-timeout 90
</span><span class='line'>(default value is 15s)</span></code></pre></td></tr></table></div></figure>


<h2>Recovery thread timout</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>heartbeat_map is_healthy 'OSD::recovery_tp thread 0x7f4c2edab700' had timed out after 30</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ceph tell osd.XX injectargs --osd-recovery-thread-timeout 180
</span><span class='line'>(default value is 30s)</span></code></pre></td></tr></table></div></figure>


<p>For more details, please refer to ceph documentation :</p>

<p><a href="http://docs.ceph.com/docs/master/rados/configuration/osd-config-ref/">http://docs.ceph.com/docs/master/rados/configuration/osd-config-ref/</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/01/27/erasure-code-on-small-clusters/">Erasure Code on Small Clusters</a></h1>
    
    
      <p class="meta">
        








  



<time datetime="2017-01-27T16:47:51+01:00" pubdate data-updated="true" class="updated">Jan 27<span>th</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Erasure code is rather designed for clusters with a sufficient size. However if you want to use it with a small amount of hosts you can also adapt the crushmap for a better matching distribution to your need.</p>

<p>Here a first example for distributing data with 1 host OR 2 drive fault tolerance with k=4, m=2 on 3 hosts and more.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>rule erasure_ruleset {
</span><span class='line'>  ruleset X
</span><span class='line'>  type erasure
</span><span class='line'>  min_size 6
</span><span class='line'>  max_size 6
</span><span class='line'>  step take default
</span><span class='line'>  step choose indep 3 type host
</span><span class='line'>  step choose indep 2 type osd
</span><span class='line'>  step emit
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>




</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2017/01/27/erasure-code-on-small-clusters/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/01/23/crushmap-for-2-dc/">Crushmap for 2 DC</a></h1>
    
    
      <p class="meta">
        








  



<time datetime="2017-01-23T10:04:14+01:00" pubdate data-updated="true" class="updated">Jan 23<span>rd</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>An example of crushmap for 2 Datacenter replication :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>rule replicated_ruleset {
</span><span class='line'>  ruleset X
</span><span class='line'>  type replicated
</span><span class='line'>  min_size 2
</span><span class='line'>  max_size 3
</span><span class='line'>  step take default
</span><span class='line'>  step choose firstn 2 type datacenter
</span><span class='line'>  step chooseleaf firstn -1 type host
</span><span class='line'>  step emit
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>This working well with pool size=2 (not recommended!) or 3.
If you set pool size more than 3 (and increase the max_size in crush), be careful : you will have n-1 replica on one side and only one on the other datacenter.</p>

<p>If you want to be able to write data even when one of the datacenters is inaccessible, pool min_size should be set at 1 even if size is set to 3. In this case, pay attention to the monitors location.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2017/01/23/crushmap-for-2-dc/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/01/20/change-log-level-on-the-fly-to-ceph-daemons/">Change Log Level on the Fly to Ceph Daemons</a></h1>
    
    
      <p class="meta">
        








  



<time datetime="2017-01-20T11:55:53+01:00" pubdate data-updated="true" class="updated">Jan 20<span>th</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Aaahhh full disk this morning.
Sometimes the logs can go crazy, and the files can quickly reach several gigabytes.</p>

<p>Show debug option (on host) :</p>

<pre><code># Look at log file
tail -n 1000 /var/log/ceph/ceph-osd.33.log

# Check debug levels
ceph daemon osd.33 config show | grep '"debug_'
    "debug_none": "0\/5",
    "debug_lockdep": "0\/1",
    "debug_context": "0\/1",
    "debug_crush": "1\/1",
    "debug_mds": "1\/5",
    ...
    "debug_filestore": "1\/5",
    ...
</code></pre>

<p>In my case it was about filestore, so &ldquo;ceph tell&rdquo; is my friend to apply the new value to the whole cluster (on admin host) :</p>

<pre><code>ceph tell osd.* injectargs --debug-filestore 0/5
</code></pre>

<p>Now you can remove the log file on reopen it :</p>

<pre><code>rm /var/log/ceph/ceph-osd.33.log

ceph daemon osd.33 log reopen
</code></pre>

<p>Then it will remain to be added in the ceph.conf file (on each osd hosts) :</p>

<pre><code>[osd]
        debug filestore = 0/5
</code></pre>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2017/01/20/change-log-level-on-the-fly-to-ceph-daemons/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2017/01/06/main-new-features-in-the-latest-versions-of-ceph/">Main New Features in the Latest Versions of Ceph</a></h1>
    
    
      <p class="meta">
        








  



<time datetime="2017-01-06T14:19:08+01:00" pubdate data-updated="true" class="updated">Jan 6<span>th</span>, 2017</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>It&rsquo;s always pleasant to see how fast new features appear in Ceph. :)</p>

<p>Here is a non-exhaustive list of some of theme on the latest releases :</p>

<h2>Kraken (October 2016)</h2>

<ul>
<li>BlueStore declared as stable</li>
<li>AsyncMessenger</li>
<li>RGW : metadata indexing via Elasticseasrch, index resharding, compression</li>
<li>S3 bucket lifecycle API, RGW Export NFS version 3 throw Ganesha</li>
<li>Rados support overwrites on erasure-coded pools / RBD on erasure coded pool (experimental)</li>
</ul>


<h2>Jewel (April 2016)</h2>

<ul>
<li>CephFS declared as stable</li>
<li>RGW multisite rearchitected (Allow active/active configuration)</li>
<li>AWS4 compatibility</li>
<li>RBD mirroring</li>
<li>BlueStore (experimental)</li>
</ul>


</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2017/01/06/main-new-features-in-the-latest-versions-of-ceph/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/05/26/check-osd-version/">Check OSD Version</a></h1>
    
    
      <p class="meta">
        








  



<time datetime="2016-05-26T14:45:04+02:00" pubdate data-updated="true" class="updated">May 26<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Occasionally it may be useful to check the version of the OSD on the entire cluster :</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>ceph tell osd.* version
</span></code></pre></td></tr></table></div></figure>


</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2016/05/26/check-osd-version/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/05/24/find-the-osd-location/">Find the OSD Location</a></h1>
    
    
      <p class="meta">
        








  



<time datetime="2016-05-24T19:24:59+02:00" pubdate data-updated="true" class="updated">May 24<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Of course, the simplest way is using the command <code>ceph osd tree</code>.</p>

<p>Note that, if an osd is down, you can see &ldquo;last address&rdquo; in <code>ceph health detail</code> :</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph health detail
</span><span class='line'>...
</span><span class='line'>osd.37 is down since epoch 16952, last address 172.16.4.68:6804/628
</span></code></pre></td></tr></table></div></figure>


<p>Also, you can use:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph osd find 37
</span><span class='line'><span class="o">{</span>
</span><span class='line'>    <span class="s2">&quot;osd&quot;</span>: 37,
</span><span class='line'>    <span class="s2">&quot;ip&quot;</span>: <span class="s2">&quot;172.16.4.68:6804\/636&quot;</span>,
</span><span class='line'>    <span class="s2">&quot;crush_location&quot;</span>: <span class="o">{</span>
</span><span class='line'>        <span class="s2">&quot;datacenter&quot;</span>: <span class="s2">&quot;pa2.ssdr&quot;</span>,
</span><span class='line'>        <span class="s2">&quot;host&quot;</span>: <span class="s2">&quot;lxc-ceph-main-front-osd-03.ssdr&quot;</span>,
</span><span class='line'>        <span class="s2">&quot;physical-host&quot;</span>: <span class="s2">&quot;store-front-03.ssdr&quot;</span>,
</span><span class='line'>        <span class="s2">&quot;rack&quot;</span>: <span class="s2">&quot;pa2-104.ssdr&quot;</span>,
</span><span class='line'>        <span class="s2">&quot;root&quot;</span>: <span class="s2">&quot;ssdr&quot;</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>To get partition UUID, you can use <code>ceph osd dump</code> (see at the end of the line) :</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph osd dump | grep ^osd.37
</span><span class='line'>osd.37 down out weight 0 up_from 56847 up_thru 57230 down_at 57538 last_clean_interval <span class="o">[</span>56640,56844<span class="o">)</span> 172.16.4.72:6801/16852 172.17.2.37:6801/16852 172.17.2.37:6804/16852 172.16.4.72:6804/16852 exists d7ab9ac1-c68c-4594-b25e-48d3a7cfd182
</span><span class='line'>
</span><span class='line'><span class="nv">$ </span>ssh 172.17.2.37 | blkid | grep d7ab9ac1-c68c-4594-b25e-48d3a7cfd182
</span><span class='line'>/dev/sdg1: <span class="nv">UUID</span><span class="o">=</span><span class="s2">&quot;98594f17-eae5-45f8-9e90-cd25a8f89442&quot;</span> <span class="nv">TYPE</span><span class="o">=</span><span class="s2">&quot;xfs&quot;</span> <span class="nv">PARTLABEL</span><span class="o">=</span><span class="s2">&quot;ceph data&quot;</span> <span class="nv">PARTUUID</span><span class="o">=</span><span class="s2">&quot;d7ab9ac1-c68c-4594-b25e-48d3a7cfd182&quot;</span>
</span><span class='line'><span class="c">#(Depending on how the partitions are created, PARTUUID label is not necessarily present.)</span>
</span></code></pre></td></tr></table></div></figure>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/04/14/lxc-2-dot-0-0-first-support-for-ceph-rbd/">LXC 2.0.0 First Support for Ceph RBD</a></h1>
    
    
      <p class="meta">
        








  



<time datetime="2016-04-14T14:10:12+02:00" pubdate data-updated="true" class="updated">Apr 14<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>FYI, the first RBD support has been added to LXC commands.</p>

<h2>Example :</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># Install LXC 2.0.0 (ubuntu) :</span>
</span><span class='line'><span class="nv">$ </span>add-apt-repository ppa:ubuntu-lxc/lxc-stable
</span><span class='line'><span class="nv">$ </span>apt-get update
</span><span class='line'><span class="nv">$ </span>apt-get install lxc
</span><span class='line'>
</span><span class='line'><span class="c"># Add a ceph pool for lxc bloc devices :</span>
</span><span class='line'><span class="nv">$ </span>ceph osd pool create lxc 64 64
</span><span class='line'>
</span><span class='line'><span class="c"># To create the container, you only need to specify &quot;rbd&quot; backingstore :</span>
</span><span class='line'><span class="nv">$ </span>lxc-create -n ctn1 -B rbd -t debian
</span><span class='line'>/dev/rbd0
</span><span class='line'>debootstrap est /usr/sbin/debootstrap
</span><span class='line'>Checking cache download in /var/cache/lxc/debian/rootfs-jessie-amd64 ...
</span><span class='line'>Copying rootfs to /usr/lib/x86_64-linux-gnu/lxc...
</span><span class='line'>Generation complete.
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>rbd showmapped
</span><span class='line'>id pool image snap device
</span><span class='line'>0  lxc  ctn1  -    /dev/rbd0
</span><span class='line'>
</span><span class='line'><span class="nv">$ </span>rbd -p lxc info ctn1
</span><span class='line'>rbd image <span class="s1">&#39;ctn1&#39;</span>:
</span><span class='line'>  size 1024 MB in 256 objects
</span><span class='line'>  order 22 <span class="o">(</span>4096 kB objects<span class="o">)</span>
</span><span class='line'>  block_name_prefix: rb.0.1217d.74b0dc51
</span><span class='line'>  format: 1
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>lxc-start -n ctn1
</span><span class='line'><span class="nv">$ </span>lxc-attach -n ctn1
</span><span class='line'>ctn1<span class="nv">$ </span>mount | grep <span class="s1">&#39; / &#39;</span>
</span><span class='line'>/dev/rbd/lxc/ctn1 on / <span class="nb">type </span>ext3 <span class="o">(</span>rw,relatime,stripe<span class="o">=</span>1024,data<span class="o">=</span>ordered<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>lxc-destroy -n ctn1
</span><span class='line'>Removing image: 100% complete...done.
</span><span class='line'>Destroyed container ctn1
</span></code></pre></td></tr></table></div></figure>




</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2016/04/14/lxc-2-dot-0-0-first-support-for-ceph-rbd/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/13/downgrade-lsi-9207-to-p19-firmware/">Downgrade LSI 9207 to P19 Firmware</a></h1>
    
    
      <p class="meta">
        








  



<time datetime="2015-08-13T10:48:31+02:00" pubdate data-updated="true" class="updated">Aug 13<span>th</span>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>After numerous problems encountered with the P20 firmware on this card model, here are the steps I followed to flash in P19 Version.</p>

<p>Since, no more problems :)</p>

<p>The model of the card is a LSI 9207-8i (SAS2308 controler) with IT FW:</p>

<pre><code>lspci | grep LSI
01:00.0 Serial Attached SCSI controller: LSI Logic / Symbios Logic SAS2308 PCI-Express Fusion-MPT SAS-2 (rev 05)
</code></pre>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/08/13/downgrade-lsi-9207-to-p19-firmware/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2017/07/28/how-many-mouvement-when-i-add-a-replica/">How Many Mouvement When I Add a Replica ?</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/03/03/dealing-with-some-osd-timeouts/">Dealing With Some Osd Timeouts</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/01/27/erasure-code-on-small-clusters/">Erasure Code on Small Clusters</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/01/23/crushmap-for-2-dc/">Crushmap for 2 DC</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/01/20/change-log-level-on-the-fly-to-ceph-daemons/">Change Log Level on the Fly to Ceph Daemons</a>
      </li>
    
      <li class="post">
        <a href="/blog/2017/01/06/main-new-features-in-the-latest-versions-of-ceph/">Main New Features in the Latest Versions of Ceph</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/05/26/check-osd-version/">Check OSD Version</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/05/24/find-the-osd-location/">Find the OSD Location</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/04/14/lxc-2-dot-0-0-first-support-for-ceph-rbd/">LXC 2.0.0 First Support for Ceph RBD</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/13/downgrade-lsi-9207-to-p19-firmware/">Downgrade LSI 9207 to P19 Firmware</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/06/25/get-omap-key-slash-value-size/">Get OMAP Key/value Size</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/06/22/the-kernel-4-dot-1-is-out/">The Kernel 4.1 Is Out</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/06/18/add-support-of-curl-multi-wait-for-radosgw-on-debian-wheezy/">Add Support of Curl_multi_wait for RadosGW on Debian Wheezy</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/05/19/intel-520-ssd-journal/">Intel 520 SSD Journal</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/05/12/radosgw-big-index/">RadosGW Big Index</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/ksperis">@ksperis</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'ksperis',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2017 - Laurent Barbe -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'cephnotes';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
